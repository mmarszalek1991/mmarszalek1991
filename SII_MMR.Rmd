---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
#Import file into R

library(aws.s3)
Sys.setenv(
"AWS_ACCESS_KEY_ID" = "***",
"AWS_SECRET_ACCESS_KEY" = "***",
"AWS_DEFAULT_REGION" = "***")
check_region = F
bucketlist()
data.table::rbindlist(get_bucket(bucket = "***"))

mmr_compass <- s3read_using(FUN = read.csv, object = "***")


LSOA_lookup <- read.csv("***.csv")
MSOA_lookup <- read.csv("***.csv")

LSOA_IMD_tercile <- read_dta("***.dta")

```

```{r}
#Load relevant packages
library(dplyr)
library(reshape2)
library(stringr)
library("geojsonR")
library(haven)
library(PHEindicatormethods)
```


```{r}
#remove SystemOne practices

'%!in%' <- Negate('%in%')

S1_Practices <- c("Y00155", "F86657", "F86025", "F86004", "F86638", "F86074", "F86018", 	
"F86026", "F86013", "F82680", "F86082")
mmr_compass <- mmr_compass[which(mmr_compass$Ods_code %!in% S1_Practices), ]

#remove City practices
#Rename column in file to then remove City practices
mmr_compass <- mmr_compass %>%
  rename(Lsoa_2011_code = Lsoa_2011_code_datregstart)

url_path_2 <- "https://raw.githubusercontent.com/drkane/geo-lookups/master/boundaries/lsoa11/E09000001.geojson"
City <- geojsonsf::geojson_sf(url_path_2)

City <- City %>%
  rename(Lsoa_2011_code = LSOA11CD)

'%!in%' <- Negate('%in%')


City_lsoa <- City$Lsoa_2011_code

mmr_compass <- mmr_compass[which(mmr_compass$Lsoa_2011_code %!in% City_lsoa), ]

mmr_compass[mmr_compass == ""] <- NA

#Remove invalid LSOA codes

mmr_compass <- mmr_compass %>%
  filter(!is.na(Lsoa_2011_code))

mmr_compass <- mmr_compass %>%
  filter(Lsoa_2011_code != "NULL")

mmr_compass <- mmr_compass[!grepl('W', mmr_compass$Lsoa_2011_code),]

mmr_compass <- mmr_compass[!grepl('S', mmr_compass$Lsoa_2011_code),]

mmr_compass <- mmr_compass[!grepl('U', mmr_compass$Lsoa_2011_code),]

```


```{r}
#clean data
#convert character columns to workable dates 

mmr_compass$Clinical_effective_date <- as.Date(mmr_compass$Clinical_effective_date, format = "%d/%m/%Y")
mmr_compass$Date_registered_end <- as.Date(mmr_compass$Date_registered_end, format = "%d/%m/%Y")
mmr_compass$Date_registered_start <- as.Date(mmr_compass$Date_registered_start, format = "%d/%m/%Y")

```


```{r}
#Remove excess registrations.
#Remove registrations with older start dates

mmr_compass <- mmr_compass %>%
group_by(Person_id, Date_registered_start) %>%
arrange(desc(Date_registered_start)) %>%
slice_head(n = 1)

#Remove registrations with less recent end dates

mmr_compass$Date_registered_end <- as.Date(mmr_compass$Date_registered_end)
mmr_compass$Date_registered_start <- as.Date(mmr_compass$Date_registered_start)

mmr_compass$Date_registered_end <- if_else(is.na(mmr_compass$Date_registered_end), as.Date("2050-01-01"), mmr_compass$Date_registered_end)

#Remove registrations with older end dates

mmr_compass <- mmr_compass %>%
group_by(Person_id) %>%
arrange(desc(Date_registered_end)) %>%
slice_head(n = 1)

length(unique(mmr_compass$Person_id))
summary(mmr_compass)

#Now one registration per child: 
```


```{r}
#Add in IMD decile data
LSOA_IMD_tercile <- LSOA_IMD_tercile %>%
  rename(Lsoa_2011_code = lsoa2011)

IMD_only <- LSOA_IMD_tercile[, c('Lsoa_2011_code','imddecile','imd2015score')]

mmr_compass <- merge(mmr_compass, IMD_only, by = "Lsoa_2011_code", all.x = T)

length(unique(mmr_compass$Person_id))

mmr_compass <- mmr_compass[!duplicated(mmr_compass[c("Person_id")]), ]
```


```{r}
#Create quintiles from deciles data

mmr_compass$imdquintile <- if_else(mmr_compass$imddecile == 1 & mmr_compass$imddecile ==2, '1', 'NA')

mmr_compass$imdquintile[mmr_compass$imddecile == 1] <- 1
mmr_compass$imdquintile[mmr_compass$imddecile == 2] <- 1
mmr_compass$imdquintile[mmr_compass$imddecile == 3] <- 2
mmr_compass$imdquintile[mmr_compass$imddecile == 4] <- 2
mmr_compass$imdquintile[mmr_compass$imddecile == 5] <- 3
mmr_compass$imdquintile[mmr_compass$imddecile == 6] <- 3
mmr_compass$imdquintile[mmr_compass$imddecile == 7] <- 4
mmr_compass$imdquintile[mmr_compass$imddecile == 8] <- 4
mmr_compass$imdquintile[mmr_compass$imddecile == 9] <- 5
mmr_compass$imdquintile[mmr_compass$imddecile == 10] <- 5

```


```{r}
#Remove any rows without IMD scores

mmr_compass <- mmr_compass %>%
  filter(!is.na(imd2015score))


#Separate out numerator and denominator to calculate rate later

mmr_compass_denom <- mmr_compass %>%
  filter(is.na(Codeterm))


mmr_compass <- mmr_compass %>%
  filter(!is.na(Codeterm))


```


```{r}
#create separate data tables to be able to calculate rates pre and post implementation
Pre_APL <- mmr_compass %>%
  filter(run_date < '2022-03-01')

Pre_APL_denom <- mmr_compass_denom %>%
  filter(run_date < '2022-03-01')

Post_APL <- mmr_compass %>%
  filter(run_date > '2022-03-01')

Post_APL_denom <- mmr_compass_denom %>%
  filter(run_date > '2022-03-01')

```

```{r}

#Need to calculate weighted rate of MMR coverage per Quintile:pre, then post, then combine.

pre_dataMMR_SII <- table(Pre_APL$imdquintile)
pre_dataMMR_SII <- as.data.frame(pre_dataMMR_SII)

#rename column name to run_date
pre_dataMMR_SII <- pre_dataMMR_SII %>%
  rename(imdquintile = Var1)

pre_dataMMR_SII <- pre_dataMMR_SII %>%
  rename(Num = Freq)

dataMMRdenom_SII <- table(Pre_APL_denom$imdquintile)

dataMMRdenom_SII <- as.data.frame(dataMMRdenom_SII)

#rename column name to run_date
dataMMRdenom_SII <- dataMMRdenom_SII %>%
  rename(imdquintile = Var1)

pre_dataMMR_SII <- merge(pre_dataMMR_SII, dataMMRdenom_SII, by = "imdquintile")

pre_dataMMR_SII$Denom <- with(pre_dataMMR_SII, Num + Freq)

pre_dataMMR_SII <- select(pre_dataMMR_SII, -c(Freq))
pre_dataMMR_SII$rate <- with(pre_dataMMR_SII, Num/Denom*100)

pre_dataMMR_SII$Int <- "pre"


fwrite(pre_dataMMR_SII, "//Users/milenamarszalek/Documents/Documents\ -\ Milena’s\ MacBook\\pre_dataMMR_SII.csv")

```


```{r}
#calculate separate standard errors for the values, which are required to calculate SII

Pre_APL_All <- rbind(Pre_APL, Pre_APL_denom)

Pre_APL_All$Outcome <- "1"
Pre_APL_All$Outcome <- as.numeric(Pre_APL_All$Outcome)

Pre_APL_All[Pre_APL_All == ""] <- NA

Pre_APL_All$Outcome <- if_else(is.na(Pre_APL_All$Codeterm), 0, Pre_APL_All$Outcome)
```


```{r}
#Each quintile becomes a separate data table so that separate standard errors can be calculated
Pre_APL_Quint1 <- Pre_APL_All %>%
  filter(imdquintile == 1)


Pre_APL_Quint2 <- Pre_APL_All %>%
  filter(imdquintile == 2)


Pre_APL_Quint3 <- Pre_APL_All %>%
  filter(imdquintile == 3)


Pre_APL_Quint4 <- Pre_APL_All %>%
  filter(imdquintile == 4)


Pre_APL_Quint5 <- Pre_APL_All %>%
  filter(imdquintile == 5)

```


```{r}
#Quint 1
mean_Quint_1 <- mean(Pre_APL_Quint1$Outcome == 1)
sd_1 <- sd(Pre_APL_Quint1$Outcome == 1)
sample.n <- length(Pre_APL_Quint1$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_1 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_1_lower.bound <- mean_Quint_1 - margin.error
Quint_1_upper.bound <- mean_Quint_1 + margin.error
```


```{r}
#Quint 2
mean_Quint_2 <- mean(Pre_APL_Quint2$Outcome == 1)
sd_1 <- sd(Pre_APL_Quint2$Outcome == 1)
sample.n <- length(Pre_APL_Quint2$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_2 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_2_lower.bound <- mean_Quint_2 - margin.error
Quint_2_upper.bound <- mean_Quint_2 + margin.error
```


```{r}
#Quint 3
mean_Quint_3 <- mean(Pre_APL_Quint3$Outcome == 1)
sd_1 <- sd(Pre_APL_Quint3$Outcome == 1)
sample.n <- length(Pre_APL_Quint3$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_3 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_3_lower.bound <- mean_Quint_3 - margin.error
Quint_3_upper.bound <- mean_Quint_3 + margin.error
```


```{r}
#Quint 4
mean_Quint_4 <- mean(Pre_APL_Quint4$Outcome == 1)
sd_1 <- sd(Pre_APL_Quint4$Outcome == 1)
sample.n <- length(Pre_APL_Quint4$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_4 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_4_lower.bound <- mean_Quint_4 - margin.error
Quint_4_upper.bound <- mean_Quint_4 + margin.error
```


```{r}
#Quint 5
mean_Quint_5 <- mean(Pre_APL_Quint5$Outcome == 1)
sd_1 <- sd(Pre_APL_Quint5$Outcome == 1)
sample.n <- length(Pre_APL_Quint5$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_5 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_5_lower.bound <- mean_Quint_5 - margin.error
Quint_5_upper.bound <- mean_Quint_5 + margin.error


pre_dataMMR_SII <- read.csv("/Users/milenamarszalek/Downloads/pre_dataMMR_SII.csv")

```

```{r}
#Need to calculate weighted rate of MMR coverage per Quintile:pre, then post, then combine.

post_dataMMR_SII <- table(Post_APL$imdquintile)
post_dataMMR_SII <- as.data.frame(post_dataMMR_SII)

#rename column name to run_date
post_dataMMR_SII <- post_dataMMR_SII %>%
  rename(imdquintile = Var1)

post_dataMMR_SII <- post_dataMMR_SII %>%
  rename(Num = Freq)

dataMMRdenom_SII <- table(Post_APL_denom$imdquintile)

dataMMRdenom_SII <- as.data.frame(dataMMRdenom_SII)

#rename column name to run_date
dataMMRdenom_SII <- dataMMRdenom_SII %>%
  rename(imdquintile = Var1)

post_dataMMR_SII <- merge(post_dataMMR_SII, dataMMRdenom_SII, by = "imdquintile")

post_dataMMR_SII$Denom <- with(post_dataMMR_SII, Num + Freq)

post_dataMMR_SII <- select(post_dataMMR_SII, -c(Freq))
post_dataMMR_SII$rate <- with(post_dataMMR_SII, Num/Denom*100)

post_dataMMR_SII$Int <- "post"


fwrite(post_dataMMR_SII, "//Users/milenamarszalek/Documents/Documents\ -\ Milena’s\ MacBook\\post_dataMMR_SII.csv")
```


```{r}

#calculate separate standard errors for the values 

Post_APL_All <- rbind(Post_APL, Post_APL_denom)

Post_APL_All$Outcome <- "1"
Post_APL_All$Outcome <- as.numeric(Post_APL_All$Outcome)

Post_APL_All[Post_APL_All == ""] <- NA

Post_APL_All$Outcome <- if_else(is.na(Post_APL_All$Codeterm), 0, Post_APL_All$Outcome)
```


```{r}
Post_APL_Quint1 <- Post_APL_All %>%
  filter(imdquintile == 1)


Post_APL_Quint2 <- Post_APL_All %>%
  filter(imdquintile == 2)


Post_APL_Quint3 <- Post_APL_All %>%
  filter(imdquintile == 3)


Post_APL_Quint4 <- Post_APL_All %>%
  filter(imdquintile == 4)


Post_APL_Quint5 <- Post_APL_All %>%
  filter(imdquintile == 5)

```


```{r}
#Quint 1
mean_Quint_1 <- mean(Post_APL_Quint1$Outcome == 1)
sd_1 <- sd(Post_APL_Quint1$Outcome == 1)
sample.n <- length(Post_APL_Quint1$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_1 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_1_lower.bound <- mean_Quint_1 - margin.error
Quint_1_upper.bound <- mean_Quint_1 + margin.error


#Quint 2
mean_Quint_2 <- mean(Post_APL_Quint2$Outcome == 1)
sd_1 <- sd(Post_APL_Quint2$Outcome == 1)
sample.n <- length(Post_APL_Quint2$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_2 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_2_lower.bound <- mean_Quint_2 - margin.error
Quint_2_upper.bound <- mean_Quint_2 + margin.error

#Quint 3
mean_Quint_3 <- mean(Post_APL_Quint3$Outcome == 1)
sd_1 <- sd(Post_APL_Quint3$Outcome == 1)
sample.n <- length(Post_APL_Quint3$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_3 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_3_lower.bound <- mean_Quint_3 - margin.error
Quint_3_upper.bound <- mean_Quint_3 + margin.error

#Quint 4
mean_Quint_4 <- mean(Post_APL_Quint4$Outcome == 1)
sd_1 <- sd(Post_APL_Quint4$Outcome == 1)
sample.n <- length(Post_APL_Quint4$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_4 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_4_lower.bound <- mean_Quint_4 - margin.error
Quint_4_upper.bound <- mean_Quint_4 + margin.error

#Quint 5
mean_Quint_5 <- mean(Post_APL_Quint5$Outcome == 1)
sd_1 <- sd(Post_APL_Quint5$Outcome == 1)
sample.n <- length(Post_APL_Quint5$Outcome)
se <- sd_1/sqrt(sample.n)
se_Quint_5 <- se*100

alpha = 0.05
degrees.freedom = sample.n - 1
t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)
print(t.score)

margin.error <- t.score * se

Quint_5_lower.bound <- mean_Quint_5 - margin.error
Quint_5_upper.bound <- mean_Quint_5 + margin.error
```


```{r}
#Data table that combines SEs with data for both pre and post implementation is exported to Excel for ease, then reimported into R
#Modified tables are then ready to be used to calculate SII
post_dataMMR_SII <- read.csv("/Users/milenamarszalek/Downloads/post_dataMMR_SII.csv")

```


```{r}
#Confidence Intervals, Standard Error
#Then calculate difference in SII between pre and post implementation


dataMMR_SII <- rbind(pre_dataMMR_SII, post_dataMMR_SII)

phe_sii(group_by(dataMMR_SII, Int),
        imdquintile,
        Denom,
        value_type = 0, # default normal distribution
        value = rate,
        lower_cl = LL_CI,
        upper_cl = UL_CI,
        confidence = 0.95,
        rii = TRUE,
        type = "standard")

phe_sii(group_by(dataMMR_SII, Int),
        imdquintile,
        Denom,
        value_type = 0,
        value = rate,
        se = SE,
        confidence = 0.95,
        rii = TRUE,
        type = "standard")
```


```{r}

library(plotrix)

SII_MMR$Intervention.Period <- as.factor(SII_MMR$Intervention.Period)

#Bar chart comparing SII pre and post intervention

ggplot(SII_MMR, aes(x = Intervention.Period, y = SlI, fill = Intervention.Period)) + geom_bar(stat = "identity", color = "black", position = position_dodge()) + xlab("Intervention Period") + ylab("Slope Index of Inequality") + geom_errorbar(aes(ymin=LL_CI, ymax = UL_CI), width = .8, linewidth = .8, position = position_dodge(0.9), color = "black") + theme_classic() + theme(axis.title = element_text(size = 15, color = "black", face = "bold")) + theme(axis.text = element_text(size = 10))
```



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

